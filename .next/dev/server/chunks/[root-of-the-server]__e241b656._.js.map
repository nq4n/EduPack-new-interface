{
  "version": 3,
  "sources": [],
  "sections": [
    {"offset": {"line": 46, "column": 0}, "map": {"version":3,"sources":["file:///C:/Users/Windows%2011/Desktop/%D9%85%D8%B4%D8%B1%D9%88%D8%B9%20%D8%A7%D9%84%D8%AA%D8%AE%D8%B1%D8%AC/EduPack-new-interface/app/api/scorm/chat/route.ts"],"sourcesContent":["import { NextRequest, NextResponse } from 'next/server';\r\nimport OpenAI from 'openai';\r\nimport { getOpenRouterConfig } from '@/lib/env';\r\n\r\nexport async function POST(req: NextRequest) {\r\n  try {\r\n    const { apiKey, model } = getOpenRouterConfig();\r\n    const openrouter = new OpenAI({\r\n      baseURL: \"https://openrouter.ai/api/v1\",\r\n      apiKey,\r\n    });\r\n\r\n    const { messages } = await req.json();\r\n\r\n    if (messages.length === 0) {\r\n      return NextResponse.json({ error: 'Messages are required' }, { status: 400 });\r\n    }\r\n\r\n    const completion = await openrouter.chat.completions.create({\r\n      model,\r\n      messages,\r\n    });\r\n\r\n    return NextResponse.json(completion.choices[0].message);\r\n  } catch (error) {\r\n    console.error('Error calling OpenRouter:', error);\r\n    const message = error instanceof Error ? error.message : 'Internal Server Error'\r\n    return NextResponse.json({ error: message }, { status: 500 });\r\n  }\r\n}\r\n"],"names":[],"mappings":";;;;AAAA;AACA;AAAA;;;;;;;;;AAGO,eAAe,KAAK,GAAgB;IACzC,IAAI;QACF,MAAM,EAAE,MAAM,EAAE,KAAK,EAAE,GAAG;QAC1B,MAAM,aAAa,IAAI,mLAAM,CAAC;YAC5B,SAAS;YACT;QACF;QAEA,MAAM,EAAE,QAAQ,EAAE,GAAG,MAAM,IAAI,IAAI;QAEnC,IAAI,SAAS,MAAM,KAAK,GAAG;YACzB,OAAO,gJAAY,CAAC,IAAI,CAAC;gBAAE,OAAO;YAAwB,GAAG;gBAAE,QAAQ;YAAI;QAC7E;QAEA,MAAM,aAAa,MAAM,WAAW,IAAI,CAAC,WAAW,CAAC,MAAM,CAAC;YAC1D;YACA;QACF;QAEA,OAAO,gJAAY,CAAC,IAAI,CAAC,WAAW,OAAO,CAAC,EAAE,CAAC,OAAO;IACxD,EAAE,OAAO,OAAO;QACd,QAAQ,KAAK,CAAC,6BAA6B;QAC3C,MAAM,UAAU,iBAAiB,QAAQ,MAAM,OAAO,GAAG;QACzD,OAAO,gJAAY,CAAC,IAAI,CAAC;YAAE,OAAO;QAAQ,GAAG;YAAE,QAAQ;QAAI;IAC7D;AACF"}}]
}